scala> spark.sql("""select * from checkarray_tab""").show
+---+----+-----+---+------+--------+
| id|name|  sal|loc|deptno|Modified|
+---+----+-----+---+------+--------+
|101|   A|10000|AMT|    10|99999999|
|102|   B|12000|BAN|    20|99999999|
|103|   C|12300|GDP|    30|99999999|
|104|   D|12500|GNT|    40|99999999|
|105|   E|13000|HYD|    50|99999999|
|106|   F|14000|MUM|    60|99999999|
|107|   G|14300|NRT|    70|99999999|
|108|   H|14500|PUN|    80|99999999|
|109|   I|16000|SAP|    90|99999999|
|110|   J|18900|VIZ|   100|99999999|
+---+----+-----+---+------+--------+

scala> val df1 = spark.sql("""select id as ID,collect_list(named_struct("NAME",trim(nvl(name,' ')),"SAL",trim(nvl(sal,' ')),"MODIFIED",case when modified = 99999999 then 99991231 else trim(nvl(modified,' ')) end,"LOC",trim(nvl(loc,' ')))) as claim from checkarray_tab group by id""")
df1: org.apache.spark.sql.DataFrame = [ID: int, claim: array<struct<NAME:string,SAL:string,MODIFIED:string,LOC:string>>]

scala> val df2 = spark.sql("""select id as ID,collect_list(named_struct("NAME",trim(nvl(name,' ')),"SAL",trim(nvl(sal,' ')),"MODIFIED",case when modified = 99999999 then 99991231 else trim(nvl(modified,' ')) end,"LOC",trim(nvl(loc,' ')),"DEPTNO",trim(nvl(deptno,' ')))) as follow_up from checkarray_tab group by id""")
df2: org.apache.spark.sql.DataFrame = [ID: int, follow_up: array<struct<NAME:string,SAL:string,MODIFIED:string,LOC:string,DEPTNO:string>>]

scala> df1.show()
+---+--------------------+
| ID|               claim|
+---+--------------------+
|108|[[H,14500,9999123...|
|101|[[A,10000,9999123...|
|103|[[C,12300,9999123...|
|107|[[G,14300,9999123...|
|102|[[B,12000,9999123...|
|109|[[I,16000,9999123...|
|105|[[E,13000,9999123...|
|110|[[J,18900,9999123...|
|106|[[F,14000,9999123...|
|104|[[D,12500,9999123...|
+---+--------------------+


scala> df2.show()
+---+--------------------+
| ID|           follow_up|
+---+--------------------+
|108|[[H,14500,9999123...|
|101|[[A,10000,9999123...|
|103|[[C,12300,9999123...|
|107|[[G,14300,9999123...|
|102|[[B,12000,9999123...|
|109|[[I,16000,9999123...|
|105|[[E,13000,9999123...|
|110|[[J,18900,9999123...|
|106|[[F,14000,9999123...|
|104|[[D,12500,9999123...|
+---+--------------------+


scala> df1.join(df2,df1("ID") === df2("ID")).show
+---+--------------------+---+--------------------+                             
| ID|               claim| ID|           follow_up|
+---+--------------------+---+--------------------+
|108|[[H,14500,9999123...|108|[[H,14500,9999123...|
|101|[[A,10000,9999123...|101|[[A,10000,9999123...|
|103|[[C,12300,9999123...|103|[[C,12300,9999123...|
|107|[[G,14300,9999123...|107|[[G,14300,9999123...|
|102|[[B,12000,9999123...|102|[[B,12000,9999123...|
|109|[[I,16000,9999123...|109|[[I,16000,9999123...|
|105|[[E,13000,9999123...|105|[[E,13000,9999123...|
|110|[[J,18900,9999123...|110|[[J,18900,9999123...|
|106|[[F,14000,9999123...|106|[[F,14000,9999123...|
|104|[[D,12500,9999123...|104|[[D,12500,9999123...|
+---+--------------------+---+--------------------+


scala> 
