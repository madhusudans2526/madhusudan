val file = spark.read.csv("file:///home/hadoop/prac/spark/requirements/dnc_pdpc_file.csv")

file.show

val process_df = file.filter(col("_c0").contains("Processed Date")).select("_c1").withColumn("parsedate", to_date(unix_timestamp($"_c1", "M/dd/yyyy").cast("timestamp"))).withColumn("scrubbed_date",date_format(col("parsedate"),"yyyyMMdd")).drop("_c1","parsedate")

process_df.show

val expiry_df = file.filter(col("_c0").contains("Result Expiry Date")).select("_c1").withColumn("expiry_col", to_date(unix_timestamp($"_c1", "M/dd/yyyy").cast("timestamp"))).withColumn("expiry_date",date_format(col("expiry_col"),"yyyyMMdd")).drop("_c1","expiry_col")

expiry_df.show

val val_file = file.na.drop().show()

val val_file = file.na.drop().toDF("phone_no","no_call","no_msg","no_fax")

val_file.show

process_df.show

expiry_df.show

val_file.createOrReplaceTempView("records_tab")

process_df.createOrReplaceTempView("process_tab")

expiry_df.createOrReplaceTempView("expiry_tab")
